# -*- coding: utf-8 -*-
"""TB-Aware GPT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/166MSk-z8l9M_QuEBW0rTgLnjr6r_dLDJ
"""

! pip install PyPDF2

! pip install chromadb

from openai import OpenAI
import gradio as gr
import os
import PyPDF2
import chromadb
from dotenv import load_dotenv

os.environ["OPENAI_API_KEY"] = "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"

load_dotenv()
from openai import OpenAI
client = OpenAI(api_key="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")

# Initialize ChromaDB
chroma_client = chromadb.Client()
collection = chroma_client.create_collection(name="TB-PDFs")

def extract_text_from_pdf(pdf_path):
    """Extract text from PDF file"""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
    return text

def chunk_text(text, chunk_size=1000):
    """Split text into chunks"""
    words = text.split()
    chunks = []
    for i in range(0, len(words), chunk_size):
        chunk = " ".join(words[i:i + chunk_size])
        chunks.append(chunk)
    return chunks

def store_pdf_in_db(pdf_path):
    """Extract, chunk and store PDF in ChromaDB"""
    try:
        text = extract_text_from_pdf(pdf_path)
        chunks = chunk_text(text)

        # Clear existing data
        collection.delete(where={"filename": "National-Guidelines-for-Management-of-DR-TB_Final.pdf"})

        # Add chunks to ChromaDB
        for i, chunk in enumerate(chunks):
            collection.add(
                documents=[chunk],
                metadatas=[{"source": pdf_path, "chunk_id": i}],
                ids=[f"chunk_{i}"]
            )
        return f"✅ Successfully loaded {len(chunks)} chunks from {pdf_path}"
    except Exception as e:
        return f"❌ Error: {str(e)}"

def get_relevant_context(query, n_results=3):
    """Retrieve relevant context from ChromaDB"""
    results = collection.query(
        query_texts=[query],
        n_results=n_results
    )
    return "\n\n".join(results['documents'][0]) if results['documents'] else ""

def chat_with_tb_bot(message, history):
    try:
        # Get relevant context from PDF
        context = get_relevant_context(message)

        system_prompt = """You are a TB Aware Bot. Use the provided context from PDFs to answer questions accurately.
        If the context doesn't contain relevant information, use your general knowledge but mention this."""

        user_content = f"Context from PDF:\n{context}\n\nQuestion: {message}"

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.2
        )

        return response.choices[0].message.content
    except Exception as e:
        import traceback
        print("❌ Backend error:", e)
        traceback.print_exc()
        return f"❌ Error in backend: {str(e)}"

def load_pdf_and_chat(pdf_file, message, history):
    # First store the PDF
    result_msg = store_pdf_in_db(pdf_file.name)

    # Then get response
    response = chat_with_tb_bot(message, history)

    return result_msg, response

def launch_app():
    with gr.Blocks() as demo:
        gr.Markdown("# ⚛️ TB Aware chatbot with PDF RAG")

        with gr.Row():
            with gr.Column():
                pdf_input = gr.File(label="Upload PDF", file_types=[".pdf"])
                load_btn = gr.Button("Load PDF into Knowledge Base")
                load_status = gr.Textbox(label="Load Status", interactive=False)

            with gr.Column():
                chat_interface = gr.ChatInterface(
                    fn=chat_with_tb_bot,
                    title="Chat with TB Aware Bot",
                    description="Ask questions about the loaded PDF or related to TB"
                )

        # Load PDF when button clicked
        load_btn.click(
            fn=lambda pdf: store_pdf_in_db(pdf.name) if pdf else "Please upload a PDF first",
            inputs=[pdf_input],
            outputs=[load_status]
        )

    demo.launch()

# https://github.com/sumit1311singh/TB-Aware-GPT/blob/main/National-Guidelines-for-Management-of-DR-TB_Final.pdf
# https://raw.githubusercontent.com/sumit1311singh/TB-Aware-GPT/main/National-Guidelines-for-Management-of-DR-TB_Final.pdf

import requests
import os

def download_pdf_from_github(url, filename="TBAwarenessFile.pdf"):
    response = requests.get(url)
    response.raise_for_status()  # ensure no errors
    with open(filename, "wb") as f:
        f.write(response.content)
    return filename

if __name__ == "__main__":
    # Example GitHub raw URL
    github_pdf_url = "https://raw.githubusercontent.com/sumit1311singh/TB-Aware-GPT/main/National-Guidelines-for-Management-of-DR-TB_Final.pdf"

    # Download PDF
    pdf_file = download_pdf_from_github(github_pdf_url, "TBAwarenessFile.pdf")
    print(f"Downloaded PDF: {pdf_file}")

    # Store in DB
    store_pdf_in_db(pdf_file)

    # Launch app
    launch_app()